# -*- coding: utf-8 -*-
"""V2-Nisuga-CSCT-Text embeddings & semantic search

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t-egsvXxP8HuHbwU9Kb7DA8QnTsgLxBI
"""
# Commented out IPython magic to ensure Python compatibility.
# !sudo apt-get install libomp-dev

import os
import numpy as np
import faiss
from langchain.document_loaders import TextLoader
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores.faiss import FAISS

def embed_products():

    file_path = 'data/passages.txt'
    with open(file_path, 'r', encoding='latin1') as f:
        documents = f.readlines()

    repo_id = "thenlper/gte-base"

    embeddings = HuggingFaceEmbeddings(model_name=repo_id)

    faiss_index_file = "product_analyzer/models/faiss_index.index"
    if os.path.exists(faiss_index_file):
        print("DB exists")
        db = FAISS.load_local(
            faiss_index_file,
            embeddings
            )
        print("DB loaded")
    else:
        print("DB does not exist")
        db = FAISS.from_documents(
            documents,
            embeddings
            )
        db.save_local(faiss_index_file)
        print("DB saved")

    # embeddings_list = embeddings.embed_documents(docs)
    # embeddings_list_float = np.array(
    #     embeddings_list
    #     ).astype(
    #     "float32"
    #     )
    # db.index = faiss.IndexFlatL2(len(embeddings_list_float[0]))
    # db.index.add(embeddings_list_float)

    db.save_local(faiss_index_file)
    print("DB updated")

    query = "pork sausage"
    test_sample = embeddings.embed_query(query)
    test_sample = np.array([test_sample]).astype("float32")

    # k = 5
    # distances, indices = db.index.search(test_sample, k)
    #
    # print(np.array(docs)[indices])

    results = db.similarity_search(query, k=5)

    for result in results:
        print(result.to_json())

    print(db.index)