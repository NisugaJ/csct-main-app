2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2024-01-04 03:54:42 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Verifying response
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Responder is issuer
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Verifying response
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Verifying response
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Responder is issuer
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Responder is issuer
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Caching OCSP response.
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Caching OCSP response.
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Caching OCSP response.
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2024-01-04 03:54:43 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2024-01-04 03:54:43 [faker.factory] DEBUG: Not in REPL -> leaving logger event level as is.
2024-01-04 03:54:43 [scrapy_fake_useragent.middleware] INFO: Error loading User-Agent provider: scrapy_fake_useragent.providers.FakeUserAgentProvider
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.address`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.address` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.automotive`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.automotive` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.bank`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.barcode`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.barcode` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.color`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.color` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.company`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.company` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.credit_card`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.credit_card` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.currency`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.currency` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.date_time`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.date_time` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.geo`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.geo` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.internet`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.internet` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.isbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.job`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.job` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.lorem`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.lorem` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.misc`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.misc` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.passport`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.passport` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.person`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.person` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.phone_number`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.phone_number` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.ssn`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.ssn` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [scrapy_fake_useragent.middleware] DEBUG: Loaded User-Agent provider: scrapy_fake_useragent.providers.FakerProvider
2024-01-04 03:54:43 [scrapy_fake_useragent.middleware] INFO: Using '<class 'scrapy_fake_useragent.providers.FakerProvider'>' as the User-Agent provider
2024-01-04 03:54:43 [scrapy_fake_useragent.middleware] INFO: Error loading User-Agent provider: scrapy_fake_useragent.providers.FakeUserAgentProvider
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.address`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.address` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.automotive`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.automotive` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.bank`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.barcode`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.barcode` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.color`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.color` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.company`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.company` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.credit_card`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.credit_card` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.currency`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.currency` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.date_time`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.date_time` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.geo`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.geo` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.internet`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.internet` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.isbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.job`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.job` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.lorem`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.lorem` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.misc`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.misc` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.passport`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.passport` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.person`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.person` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.phone_number`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.phone_number` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [faker.factory] DEBUG: Looking for locale `en_US` in provider `faker.providers.ssn`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.ssn` has been localized to `en_US`.
2024-01-04 03:54:43 [faker.factory] DEBUG: Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.
2024-01-04 03:54:43 [scrapy_fake_useragent.middleware] DEBUG: Loaded User-Agent provider: scrapy_fake_useragent.providers.FakerProvider
2024-01-04 03:54:43 [scrapy_fake_useragent.middleware] INFO: Using '<class 'scrapy_fake_useragent.providers.FakerProvider'>' as the User-Agent provider
2024-01-04 03:54:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware',
 'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-01-04 03:54:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-01-04 03:54:43 [scrapy.middleware] INFO: Enabled item pipelines:
['supermarketscraper.supermarketscraper.pipelines.SupermarketscraperPipeline']
2024-01-04 03:54:43 [scrapy.core.engine] INFO: Spider opened
2024-01-04 03:54:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-01-04 03:54:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-01-04 03:54:43 [scrapy-playwright] INFO: Starting download handler
2024-01-04 03:54:43 [scrapy-playwright] INFO: Starting download handler
2024-01-04 03:54:43 [asyncio] ERROR: Task exception was never retrieved
future: <Task finished name='Task-3' coro=<Connection.run() done, defined at C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_connection.py:268> exception=NotImplementedError()>
Traceback (most recent call last):
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_connection.py", line 275, in run
    await self._transport.connect()
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_transport.py", line 135, in connect
    raise exc
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_transport.py", line 123, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\subprocess.py", line 221, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 1694, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 502, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError
2024-01-04 03:54:43 [asyncio] ERROR: Task exception was never retrieved
future: <Task finished name='Task-4' coro=<Connection.run() done, defined at C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_connection.py:268> exception=NotImplementedError()>
Traceback (most recent call last):
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_connection.py", line 275, in run
    await self._transport.connect()
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_transport.py", line 135, in connect
    raise exc
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_transport.py", line 123, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\subprocess.py", line 221, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 1694, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 502, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError
2024-01-04 03:54:43 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ScrapyPlaywrightDownloadHandler._engine_started of <scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler object at 0x0000021F6BAD6C10>>
Traceback (most recent call last):
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py", line 1065, in adapt
    extracted = result.result()
                ^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_playwright\handler.py", line 128, in _launch
    self.playwright = await self.playwright_context_manager.start()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\async_api\_context_manager.py", line 52, in start
    return await self.__aenter__()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\async_api\_context_manager.py", line 47, in __aenter__
    playwright = AsyncPlaywright(next(iter(done)).result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_transport.py", line 123, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\subprocess.py", line 221, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 1694, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 502, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError
2024-01-04 03:54:43 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method ScrapyPlaywrightDownloadHandler._engine_started of <scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler object at 0x0000021F6BC14D90>>
Traceback (most recent call last):
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py", line 1065, in adapt
    extracted = result.result()
                ^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_playwright\handler.py", line 128, in _launch
    self.playwright = await self.playwright_context_manager.start()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\async_api\_context_manager.py", line 52, in start
    return await self.__aenter__()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\async_api\_context_manager.py", line 47, in __aenter__
    playwright = AsyncPlaywright(next(iter(done)).result())
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_transport.py", line 123, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\subprocess.py", line 221, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 1694, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 502, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError
2024-01-04 03:54:48 [scrapy.extensions.throttle] INFO: slot: groceries.asda.com | conc: 1 | delay: 3000 ms (-2000) | latency:   79 ms | size:  1314 bytes
2024-01-04 03:54:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://groceries.asda.com/robots.txt> (referer: None)
2024-01-04 03:54:52 [py.warnings] WARNING: C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_fake_useragent\middleware.py:95: ScrapyDeprecationWarning: Attribute RetryMiddleware.EXCEPTIONS_TO_RETRY is deprecated. Use the RETRY_EXCEPTIONS setting instead.
  if isinstance(exception, self.EXCEPTIONS_TO_RETRY) \

2024-01-04 03:54:52 [root] ERROR: failure: [Failure instance: Traceback: <class 'AttributeError'>: 'ScrapyPlaywrightDownloadHandler' object has no attribute 'browser_type'
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py:735:errback
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py:798:_startRunCallbacks
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py:892:_runCallbacks
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py:1792:gotResult
--- <exception caught here> ---
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py:1693:_inlineCallbacks
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\python\failure.py:518:throwExceptionIntoGenerator
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy\core\downloader\middleware.py:54:process_request
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py:1065:adapt
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_playwright\handler.py:298:_download_request
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_playwright\handler.py:222:_create_page
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_playwright\handler.py:181:_create_browser_context
C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_playwright\handler.py:146:_maybe_launch_browser
]
2024-01-04 03:54:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://groceries.asda.com/search/meat-poultry-fish/products?page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy\utils\defer.py", line 279, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "D:\MyProjects\UWE-MSC-PROJECT\artifacts\PROJECT\main-app\supermarketscraper\supermarketscraper\spiders\AsdaSpider.py", line 214, in on_error
    failure.response.request.url,
    ^^^^^^^^^^^^^^^^
AttributeError: 'Failure' object has no attribute 'response'
2024-01-04 03:54:52 [scrapy.core.engine] INFO: Closing spider (finished)
2024-01-04 03:54:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.AttributeError': 1,
 'downloader/request_bytes': 625,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1829,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 8.952223,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 1, 4, 3, 54, 52, 654242, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 7226,
 'httpcompression/response_count': 1,
 'log_count/DEBUG': 132,
 'log_count/ERROR': 6,
 'log_count/INFO': 17,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2024, 1, 4, 3, 54, 43, 702019, tzinfo=datetime.timezone.utc)}
2024-01-04 03:54:52 [scrapy.core.engine] INFO: Spider closed (finished)
2024-01-04 03:54:52 [scrapy-playwright] INFO: Closing download handler
2024-01-04 03:54:52 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method DownloadHandlers._close of <scrapy.core.downloader.handlers.DownloadHandlers object at 0x0000021F6BA53D10>>
Traceback (most recent call last):
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py", line 1693, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\python\failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 92, in _close
    yield dh.close()
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py", line 1693, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\python\failure.py", line 518, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_playwright\handler.py", line 279, in close
    yield deferred_from_coro(self._close())
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\twisted\internet\defer.py", line 1065, in adapt
    extracted = result.result()
                ^^^^^^^^^^^^^^^
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\scrapy_playwright\handler.py", line 287, in _close
    await self.playwright_context_manager.__aexit__()
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\async_api\_context_manager.py", line 58, in __aexit__
    await self._connection.stop_async()
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_connection.py", line 286, in stop_async
    self._transport.request_stop()
  File "C:\Users\nisug\AppData\Local\pypoetry\Cache\virtualenvs\scraper-SYrxcbRP-py3.11\Lib\site-packages\playwright\_impl\_transport.py", line 101, in request_stop
    assert self._output
           ^^^^^^^^^^^^
AttributeError: 'PipeTransport' object has no attribute '_output'
2024-01-04 03:54:52 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2024-01-04 03:54:52 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2024-01-04 03:54:52 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2024-01-04 03:54:52 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2024-01-04 03:54:52 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2024-01-04 03:54:53 [httpx] DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-04 03:54:53 [httpx] DEBUG: load_verify_locations cafile='C:\\Users\\nisug\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\scraper-SYrxcbRP-py3.11\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-04 03:54:54 [httpx] DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-04 03:54:54 [httpx] DEBUG: load_verify_locations cafile='C:\\Users\\nisug\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\scraper-SYrxcbRP-py3.11\\Lib\\site-packages\\certifi\\cacert.pem'
